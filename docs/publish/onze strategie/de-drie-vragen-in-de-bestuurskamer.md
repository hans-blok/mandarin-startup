## Toelichting op de kernvragen rond agentic AI

Het fragment benoemt **drie fundamentele vragen** die ontstaan zodra agentic AI verschuift van experiment naar **organisatie-kritische inzet**. Het zijn geen technische detailvragen, maar **bestuurlijke en architectonische vraagstukken**.

---

## 1. Who is accountable for an agent’s decisions?  
**Wie is aanspreekbaar als een agent beslist of handelt?**

### Wat hiermee wordt bedoeld
Bij klassieke IT-systemen:
- maakt een **mens** de beslissingen;
- software **ondersteunt**.

Bij agentic AI:
- **neemt de agent zelfstandig beslissingen**;
- vaak zonder directe menselijke tussenkomst;
- soms over meerdere stappen en systemen heen.

Dit roept de vraag op: **wie draagt formeel verantwoordelijkheid?**
- De business owner?
- IT?
- De leverancier van het model?
- De data-eigenaar?
- Of niemand?

### Waarom dit een probleem is
Zonder expliciete verantwoordelijkheid:
- is er **geen escalatiepad**;
- geen helder eigenaarschap bij fouten;
- en geen basis voor toezicht, audit of compliance.

In boardrooms komt dit neer op de vraag:
> *“Als dit misgaat, wie moet zich verantwoorden?”*

### Impliciete zorg
Organisaties ontdekken dat ze **digitale medewerkers creëren**, maar zonder:
- functieomschrijving,
- mandaat,
- of leidinggevende.

---

## 2. How can quality and compliance be ensured across agents executing dynamically changing tasks?  
**Hoe borg je kwaliteit en compliance bij agents met dynamisch gedrag?**

### Wat hiermee wordt bedoeld
Agentic systemen:
- passen hun gedrag aan op context;
- combineren data, tools en beslissingen;
- volgen geen vast, voorspelbaar script.

Dit botst met klassieke governance, die uitgaat van:
- vooraf gedefinieerde processen;
- stabiele taken;
- statische controles.

### Concrete spanningen
- Hoe test je iets dat **anders reageert per situatie**?
- Hoe borg je privacy-, bias- en security-eisen als:
  - taken veranderen,
  - data verandert,
  - of routes door systemen verschillen?

Traditionele compliance is:
- **ex-ante** (vooraf goedkeuren).

Agentic AI vereist:
- **continue monitoring**;
- **ex-post verantwoording** (achteraf kunnen uitleggen wat er gebeurde).

### Impliciete zorg
Bestuurders realiseren zich:
> *“Onze bestaande controles zijn ontworpen voor processen, niet voor autonome besluitvorming.”*

---

## 3. Do the long-term economics of large language models and AI infrastructure hold up at enterprise scale?  
**Zijn de kosten van LLM’s en AI-infrastructuur houdbaar op enterprise-schaal?**

### Wat hiermee wordt bedoeld
Veel agent-experimenten:
- starten klein;
- met beperkte volumes;
- vaak gefinancierd uit innovatiebudgetten.

Op enterprise-schaal:
- stijgen inferentiekosten sterk;
- neemt data- en compute-verkeer toe;
- worden latency, beschikbaarheid en redundantie kritisch;
- komen kosten voor licenties, monitoring, security en governance erbij.

De kernvraag is niet:
> *“Werkt het?”*  
maar:
> *“Kunnen we dit **blijven betalen** als het kernwerk wordt?”*

### Impliciete rekensom
- Wat kost één agent per dag?
- Wat kosten duizend agents?
- Wat als ze **24/7 redeneren, plannen en controleren**?
- Hoe verhoudt dit zich tot:
  - personeelskosten,
  - marges,
  - schaalvoordelen?

### Impliciete zorg
Zonder expliciet kostenmodel:
- wordt agentic AI een **onvoorspelbare OPEX-machine**;
- en daarmee bestuurlijk onacceptabel.

---

## Samenvattend inzicht

Deze drie vragen zeggen samen:

> *Agentic AI is geen toolprobleem, maar een organisatieprobleem.*

Ze gaan over:
- **verantwoordelijkheid** (governance),
- **beheersbaarheid** (kwaliteit & compliance),
- **duurzaamheid** (economisch model).

Of anders gezegd:
- je introduceert geen software,
- je introduceert een **nieuwe vorm van arbeid**.

En arbeid vereist altijd:
- mandaat,
- toezicht,
- en een houdbaar businessmodel.
